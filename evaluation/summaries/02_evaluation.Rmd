---
title: "Evaluation of Summaries"
author: "Fabian Aiolfi"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(corrplot)
library(reshape2)
library(Metrics)
library(kableExtra)
```

```{r, include=FALSE}
broad_policy_mpolicy_avg_df <- readRDS(here("data", "evaluation", "broad_policy_mpolicy_avg_df_summaries.rds"))
broad_policy_mpolicy_avg_df <- broad_policy_mpolicy_avg_df %>% 
  drop_na() %>% 
  mutate(nanou_2017_mpolicy_lrscale3 = as.numeric(nanou_2017_mpolicy_lrscale3)) %>% 
  rename("LSS Economy" = avg_lss_econ_z_score) %>% 
  rename("LSS Social" = avg_lss_social_z_score) %>% 
  rename("RoBERT Left Right" = RoBERT_left_right_z_score) %>% 
  rename("Bakker Hobolt Economy" = bakker_hobolt_econ_z_score) %>% 
  rename("Bakker Hobolt Social" = bakker_hobolt_social_z_score) %>% 
  rename("CMP Left Right" = cmp_left_right_z_score) %>% 
  rename("ChatGPT 0-Shot" = chatgpt_summary_0_shot_z_score) %>% 
  rename("ChatGPT Ranking" = chatgpt_ranking_z_score) %>% 
  rename("Llama 0-Shot" = llama_summary_0_shot_z_score) %>% 
  rename("Llama Ranking" = llama_ranking_z_score) %>% 
  rename("Nanou 2017 (Ground Truth)" = nanou_2017_mpolicy_lrscale3)
```

## Pearson Correlation *

```{r echo=FALSE, fig.height=8, fig.width=8, message=FALSE, warning=FALSE}
pearson_correlation <- broad_policy_mpolicy_avg_df %>% 
  select(-broad_policy_area_mpolicy_moodley, -period)

pearson_correlation <- cor(pearson_correlation, use = "pairwise.complete.obs")
pearson_correlation_melt <- melt(pearson_correlation) # Convert the correlation matrix into long format for ggplot2

ggplot(pearson_correlation_melt, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  geom_text(aes(label = round(value, 2)), size = 3) +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name="Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1)) +
  coord_fixed() +
  xlab("") + ylab("") +
  theme(legend.position="none")
```


## Mean Absolute Error and Root Mean Square Error *

```{r echo=FALSE, message=FALSE, warning=FALSE}

# Define the ground truth column
ground_truth <- broad_policy_mpolicy_avg_df$`Nanou 2017 (Ground Truth)`

# Select all columns to compare (excluding the ground truth column)
columns_to_compare <- broad_policy_mpolicy_avg_df %>% 
  select(-`Nanou 2017 (Ground Truth)`, -broad_policy_area_mpolicy_moodley, -period)

# Calculate MAE for each column
mae_results <- sapply(columns_to_compare, function(column) {
  mean(abs(column - ground_truth), na.rm = TRUE) # Handle NA values if present
})

mae_results_df <- data.frame(
  Column = names(mae_results),
  MAE = round(mae_results, 2)
)

# Calculate RMSE for each column
rmse_results <- sapply(columns_to_compare, function(column) {
  sqrt(mean((column - ground_truth)^2, na.rm = TRUE)) # Handle NA values if present
})

rmse_results_df <- data.frame(
  Column = names(rmse_results),
  RMSE = round(rmse_results, 2)
)

errors_table <- mae_results_df %>% 
  left_join(rmse_results_df, by = "Column") %>% 
  arrange(MAE) %>% 
  rename("Mean Absolute Error" = MAE) %>% 
  rename("Root Mean Square Error" = RMSE) %>% 
  rename(" " = Column)
  
errors_table %>%
  kbl() %>%
  kable_styling()
```

## Variance

```{r echo=FALSE, fig.height=5, fig.width=8, message=FALSE, warning=FALSE}

variance_hist <- broad_policy_mpolicy_avg_df %>%
  select(-broad_policy_area_mpolicy_moodley, -period) %>% 
  pivot_longer(cols = everything(),
               names_to = "z_score_measurement", 
               values_to = "z_score_value")

ggplot(variance_hist, aes(x = z_score_value)) +
  geom_histogram() +
  facet_wrap(~ z_score_measurement) +
  xlab("Z-Score") + ylab("Count") +
  theme_minimal()
```




- Histogram showing (lack of) variance (Levene's Test For Equality Of Variances)
- Adjusted MAE And RMSE With Variance Penalties *
- Spearman's Rank Correlation *
- Scatter plots
- Synthesize the results of all metrics with *