---
title: "Evaluation of Summaries"
author: "Fabian Aiolfi"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(corrplot)
library(reshape2)
library(Metrics)
library(kableExtra)
library(car)
```

```{r, include=FALSE}
broad_policy_mpolicy_avg_df <- readRDS(here("data", "evaluation", "broad_policy_mpolicy_avg_df_summaries.rds"))
broad_policy_mpolicy_avg_df <- broad_policy_mpolicy_avg_df %>% 
  drop_na() %>% 
  mutate(nanou_2017_mpolicy_lrscale3 = as.numeric(nanou_2017_mpolicy_lrscale3)) %>% 
  rename("LSS Economy" = avg_lss_econ_z_score) %>% 
  rename("LSS Social" = avg_lss_social_z_score) %>% 
  rename("RoBERT Left Right" = RoBERT_left_right_z_score) %>% 
  rename("Bakker Hobolt Economy" = bakker_hobolt_econ_z_score) %>% 
  rename("Bakker Hobolt Social" = bakker_hobolt_social_z_score) %>% 
  rename("CMP Left Right" = cmp_left_right_z_score) %>% 
  rename("ChatGPT 0-Shot" = chatgpt_summary_0_shot_z_score) %>% 
  rename("ChatGPT Ranking" = chatgpt_ranking_z_score) %>% 
  rename("Llama 0-Shot" = llama_summary_0_shot_z_score) %>% 
  rename("Llama Ranking" = llama_ranking_z_score) %>% 
  rename("Nanou 2017 (Ground Truth)" = nanou_2017_mpolicy_lrscale3)

# Define the ground truth column
ground_truth <- broad_policy_mpolicy_avg_df$`Nanou 2017 (Ground Truth)`

# Select all columns to compare (excluding the ground truth column)
columns_to_compare <- broad_policy_mpolicy_avg_df %>% 
  select(-`Nanou 2017 (Ground Truth)`, -broad_policy_area_mpolicy_moodley, -period)
```

## Pearson Correlation *

```{r echo=FALSE, fig.height=8, fig.width=8, message=FALSE, warning=FALSE}
pearson_correlation <- broad_policy_mpolicy_avg_df %>% 
  select(-broad_policy_area_mpolicy_moodley, -period)

pearson_correlation <- cor(pearson_correlation, use = "pairwise.complete.obs")
pearson_correlation_melt <- melt(pearson_correlation) # Convert the correlation matrix into long format for ggplot2

ggplot(pearson_correlation_melt, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  geom_text(aes(label = round(value, 2)), size = 3) +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name="Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1)) +
  coord_fixed() +
  xlab("") + ylab("") +
  theme(legend.position="none")
```


## Mean Absolute Error and Root Mean Square Error *

```{r echo=FALSE, message=FALSE, warning=FALSE}

# Calculate MAE for each column
mae_results <- sapply(columns_to_compare, function(column) {
  mean(abs(column - ground_truth), na.rm = TRUE) # Handle NA values if present
})

mae_results_df <- data.frame(
  Column = names(mae_results),
  MAE = round(mae_results, 2)
)

# Calculate RMSE for each column
rmse_results <- sapply(columns_to_compare, function(column) {
  sqrt(mean((column - ground_truth)^2, na.rm = TRUE)) # Handle NA values if present
})

rmse_results_df <- data.frame(
  Column = names(rmse_results),
  RMSE = round(rmse_results, 2)
)

errors_table <- mae_results_df %>% 
  left_join(rmse_results_df, by = "Column") %>% 
  arrange(MAE) %>% 
  rename("Mean Absolute Error" = MAE) %>% 
  rename("Root Mean Square Error" = RMSE) %>% 
  rename(" " = Column)
  
errors_table %>%
  kbl() %>%
  kable_styling()
```

## Variance

### Distribution of Z-Scores (Histograms)

```{r echo=FALSE, fig.height=5, fig.width=8, message=FALSE, warning=FALSE}

variance_hist <- broad_policy_mpolicy_avg_df %>%
  select(-broad_policy_area_mpolicy_moodley, -period) %>% 
  pivot_longer(cols = everything(),
               names_to = "z_score_measurement", 
               values_to = "z_score_value")

ggplot(variance_hist, aes(x = z_score_value)) +
  geom_histogram() +
  facet_wrap(~ z_score_measurement) +
  xlab("Z-Score") + ylab("Count") +
  theme_minimal()
```

### Distribution of Z-Scores (Box Plots)

```{r echo=FALSE, fig.height=5, fig.width=8, message=FALSE, warning=FALSE}

variance_data <- broad_policy_mpolicy_avg_df %>%
  select(-broad_policy_area_mpolicy_moodley, -period) %>% 
  pivot_longer(cols = everything(),
               names_to = "measurement", 
               values_to = "value") %>% 
  group_by(measurement)

ggplot(variance_data) +
  geom_boxplot(aes(x = measurement, y = value)) +
  ylab("Z-Score") + xlab("") +
  coord_flip() +
  theme_minimal()
```

### Leveneâ€™s Test for Equality of Variances

```{r echo=FALSE, message=FALSE, warning=FALSE}

# Prepare a dataframe to hold the results
levene_results <- lapply(names(columns_to_compare), function(col_name) {
  # Combine ground truth and the column into a dataframe
  temp_data <- data.frame(
    value = c(ground_truth, columns_to_compare[[col_name]]),
    measurement = rep(c("Ground Truth", col_name), each = length(ground_truth))
  )
  
  # Perform Levene's Test
  test_result <- leveneTest(value ~ measurement, data = temp_data)
  
  # Extract the relevant statistics
  data.frame(
    Column = col_name,
    F_Value = test_result$`F value`[1],
    P_Value = round(test_result$`Pr(>F)`[1], 2)
  )
})

# Combine results into a single dataframe
levene_results_df <- do.call(rbind, levene_results)

levene_results_table <- levene_results_df %>% 
  select(-F_Value) %>% 
  arrange(desc(P_Value)) %>% 
  rename(" " = Column) %>% 
  rename("p-value" = P_Value)

levene_results_table %>%
  kbl() %>%
  kable_styling()
```

> If the p-value from the test is less than our chosen significance level, we can reject the null hypothesis and conclude that we have enough evidence to state that the variance among the groups is not equal.



## Adjusted MAE And RMSE With Variance Penalties *



















- Spearman's Rank Correlation *
- Scatter plots
- Synthesize the results of all metrics with *
